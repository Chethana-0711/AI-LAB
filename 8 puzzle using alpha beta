import math


MOVES = {
    'Up': (-1, 0),
    'Down': (1, 0),
    'Left': (0, -1),
    'Right': (0, 1)
}

GOAL_STATE = [[1, 2, 3],
              [4, 5, 6],
              [7, 8, 0]] 

def manhattan_distance(state):
    """Heuristic function: Manhattan distance from current state to goal."""
    distance = 0
    for i in range(3):
        for j in range(3):
            val = state[i][j]
            if val != 0:
                goal_x, goal_y = divmod(val - 1, 3)
                distance += abs(goal_x - i) + abs(goal_y - j)
    return distance

def find_blank(state):
    for i in range(3):
        for j in range(3):
            if state[i][j] == 0:
                return i, j

def generate_moves(state):
    """Generate all possible next states."""
    i, j = find_blank(state)
    moves = []
    for move, (dx, dy) in MOVES.items():
        new_i, new_j = i + dx, j + dy
        if 0 <= new_i < 3 and 0 <= new_j < 3:
            new_state = [row[:] for row in state]
            new_state[i][j], new_state[new_i][new_j] = new_state[new_i][new_j], new_state[i][j]
            moves.append((move, new_state))
    return moves

def is_goal(state):
    return state == GOAL_STATE

def print_state(state):
    for row in state:
        print(' '.join(str(x) if x != 0 else '_' for x in row))
    print()



def alpha_beta(state, depth, alpha, beta, maximizing_player):
    """Recursive alpha-beta minimax applied to the puzzle."""
    if is_goal(state) or depth == 0:
      
        return -manhattan_distance(state), []

    if maximizing_player:
        max_eval = -math.inf
        best_path = []
        for move, new_state in generate_moves(state):
            eval, path = alpha_beta(new_state, depth - 1, alpha, beta, False)
            if eval > max_eval:
                max_eval = eval
                best_path = [move] + path
            alpha = max(alpha, eval)
            if beta <= alpha:
                break 
        return max_eval, best_path
    else:
        min_eval = math.inf
        best_path = []
        for move, new_state in generate_moves(state):
            eval, path = alpha_beta(new_state, depth - 1, alpha, beta, True)
            if eval < min_eval:
                min_eval = eval
                best_path = [move] + path
            beta = min(beta, eval)
            if beta <= alpha:
                break  # Prune
        return min_eval, best_path


def main():
    print("8 Puzzle solved using Alpha-Beta Search (heuristic based).")
    print("Enter puzzle row by row (use 0 for blank):")

    start_state = []
    for i in range(3):
        row = list(map(int, input(f"Row {i+1}: ").split()))
        start_state.append(row)

    print("\nStarting puzzle:")
    print_state(start_state)

    depth = int(input("Enter search depth (e.g., 6): "))
    score, path = alpha_beta(start_state, depth, -math.inf, math.inf, True)

    print("\nHeuristic evaluation score:", score)
    print("Suggested move sequence:")
    print(" â†’ ".join(path) if path else "No moves found")

if __name__ == "__main__":
    main()
