import math
import heapq

GOAL = [[1, 2, 3],
        [4, 5, 6],
        [7, 8, 0]]  


def heuristic(state):
    distance = 0
    for r in range(3):
        for c in range(3):
            val = state[r][c]
            if val != 0:
                goal_r, goal_c = divmod(val - 1, 3)
                distance += abs(goal_r - r) + abs(goal_c - c)
    return distance


def find_blank(state):
    for r in range(3):
        for c in range(3):
            if state[r][c] == 0:
                return r, c


def successors(state):
    r, c = find_blank(state)
    moves = []
    directions = [("Up", (r-1, c)), ("Down", (r+1, c)), ("Left", (r, c-1)), ("Right", (r, c+1))]
    for move, (nr, nc) in directions:
        if 0 <= nr < 3 and 0 <= nc < 3:
            new_state = [row[:] for row in state]
            new_state[r][c], new_state[nr][nc] = new_state[nr][nc], new_state[r][c]
            moves.append((move, new_state))
    return moves


def to_tuple(state):
    return tuple(tuple(row) for row in state)


def print_board(state):
    for row in state:
        print(" ".join(str(x) if x != 0 else " " for x in row))
    print()


def alpha_beta(state, depth, alpha, beta, maximizing):
    h = heuristic(state)
    if state == GOAL:
        return -math.inf if maximizing else math.inf, [state]
    if depth == 0:
        return h if maximizing else -h, [state]

    if maximizing:
        max_eval = -math.inf
        best_path = []
        for _, succ in successors(state):
            val, path = alpha_beta(succ, depth - 1, alpha, beta, False)
            if val > max_eval:
                max_eval = val
                best_path = [state] + path
            alpha = max(alpha, val)
            if beta <= alpha:
                break
        return max_eval, best_path
    else:
        min_eval = math.inf
        best_path = []
        for _, succ in successors(state):
            val, path = alpha_beta(succ, depth - 1, alpha, beta, True)
            if val < min_eval:
                min_eval = val
                best_path = [state] + path
            beta = min(beta, val)
            if beta <= alpha:
                break
        return min_eval, best_path


def a_star(start):
    pq = []
    g = {to_tuple(start): 0}
    heapq.heappush(pq, (heuristic(start), 0, start, []))

    visited = set()

    while pq:
        f, cost, state, path = heapq.heappop(pq)
        state_t = to_tuple(state)
        if state_t in visited:
            continue
        visited.add(state_t)

        if state == GOAL:
            return path + [state]

        for move, succ in successors(state):
            new_cost = cost + 1
            succ_t = to_tuple(succ)
            if succ_t not in g or new_cost < g[succ_t]:
                g[succ_t] = new_cost
                f = new_cost + heuristic(succ)
                heapq.heappush(pq, (f, new_cost, succ, path + [state]))
    return None


def is_solvable(state):
    flat = [n for row in state for n in row if n != 0]
    inversions = sum(1 for i in range(len(flat)) for j in range(i+1, len(flat)) if flat[i] > flat[j])
    return inversions % 2 == 0


def main():
    print("8-Puzzle Solver (AI using Alpha‚ÄìBeta and A*)")
    print("Enter the initial board configuration (use 0 for blank).")

    state = []
    for i in range(3):
        row = list(map(int, input(f"Row {i+1} (3 numbers space-separated): ").split()))
        state.append(row)

    print("\nInitial Board:")
    print_board(state)

    if not is_solvable(state):
        print("this puzzle configuration is unsolvable.")
        return

    print("üîç Solving puzzle... (please wait)\n")
    path = a_star(state)  

    if path:
        print(f"puzzle solved in {len(path)-1} moves!\n")
        for step, board in enumerate(path):
            print(f"Step {step}:")
            print_board(board)
    else:
        print("no solution found.")

if __name__ == "__main__":
    main()
